function [out, act_h, act_a] = Forward(W, b, X)
% [OUT, act_h, act_a] = Forward(W, b, X) performs forward propogation on the
% input data 'X' uisng the network defined by weights and biases 'W' and 'b'
% (as generated by InitializeNetwork(..)).
%
% This function should return the final softmax output layer activations in OUT,
% as well as the hidden layer post activations in 'act_h', and the hidden layer
% pre activations in 'act_a'.

    if size(X,2) ~= 1
        X=X';
    end

    act_a = cell(1,length(W));
    act_h = cell(1,length(W));
        
    act_a{1} = W{1} * X + b{1};%repmat(b{1},1,size(X,2));
    act_h{1} = sigmoid(act_a{1});

    for i = 2:length(W)
        act_a{i} = W{i} * act_h{i-1} + b{i};%repmat(b{i},1,size(X,2));
        act_h{i} = sigmoid(act_a{i});
    end
    
    out = softmax(act_a{end});
    act_h{end} = out;

end
